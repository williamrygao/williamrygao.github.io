---
layout: default
title: Dis-belief in belief / Hineni, hineni! / A sky full of stars or a handful of dust
permalink: /triptych/
---

# Dis-belief in belief / Hineni, hineni! / A sky full of stars or a handful of dust

<p class="font3 right">26 OCTOBER 2025</p>

A longstanding distaste for belief in belief lingers in my soul. I am far from proud to admit that I continue to look askance upon this behaviour as it manifests in those around me, ~~even~~ especially my loved ones, and in my self. I don't think there exists anything more silently harmful to one's cognitive agency. For some time I believed my mathematical training had sharpened my ability to recognize self-deception, but I now think this is nonsense.

I used to bear a similarly irrational disdain for God. Not the idea of theists being evil mutants not to be trusted, no, God has felt very real to me for as long as I've felt very real to my self. I resented God because he guided my then-closest friend into suffering just about as severe as I have borne witness, all while rendering me utterly powerless with respect to their livelihood. A friend whose faith in Jesus Christ their Lord and saviour was just about as deep as I have borne witness. On one hand I am fortunate that the first Christian friend I had was living proof of religious thought beyond belief in belief; on the other hand I decided then and there that whoever God was, he could not be the God who was portrayed in the Bible. I now think the latter is nonsense. I had not even read much of the Bible by this point, and I found it difficult to do so without internally screaming "Why God, why"?

Given my track record, it may be preferable to remain oblivious about all things epistemic and spiritual. I'm doomed to be incorrect no matter what my beliefs. Incorrectness is an uncomfortable state for my puny math-battered brain, but if I want to *live*, I must lean more into incorrectness than I have. So if I can make one more epistemic claim, I think it would be more productive and more fulfilling for me to orient towards integrity rather than rationality.

Weaponizing my obliviousness is hard. I've tried for years, yet I never find myself remaining faithful to my obliviousness. One step forward, three steps backwards. I think a necessary condition to recover the integrity I lack is to believe in something (and that something must not be belief!) more cogently than I ever have. I am proud to admit that I admire those who can hold religious beliefs more deeply than belief in belief.

In fact, several curious/impossible interactions with Christians and several Dostoevsky novels later, I think Christianity is the most comprehensive account of eternalism I know. The Biblical God is infinitely opaque and infinitely benevolent. Offering his only son to be crucified in our ordinary hands, he eternally vindicates both the victim and perpetrator of violence from the hell that we create on both sides. Concretely, I'm compelled to claim that this is the only account which could reconcile the agony endured by my friend and too many others. The most lethal, all-consuming, unfortunate, irreversible lie I ever told is that I am a good person capable of doing good. Truthfully, I am a well-oiled cog in the great machinery of humans killing humans, ad infinitum. And more than I am aware, I have been complicit in the suffering of my dear friend and too many others. Looking askew, it's now clear to me that Jesus Christ is the only reason they're alive today.

---

Lightning struck itself  
Cleaves the word through frozen tapestry  
Scribbles across my etiolated eye  
Didn't you hear me calling?

In the arms of another  
Or in the blood of the swans  
Glaring as the stars skid below  
Hineni, hineni!

---

One reason why spiritual beliefs are so ineffable is that they, barring a most momentous revolution in the way we interact with reality, are neither provable nor disprovable. In other words, they don't constraint experience. And they aren't particularly willing to be discarded, should evidence of implausibility arise. Instead, believers are repeatedly instructed to 'have faith'. As far as I can tell, few religions constitutionally condemn doubt, but many religious institutions do. The effacing of doubt, one of the human mind's rare assets, and the [invisible dragon fallacy](https://www.lesswrong.com/posts/CqyJzDZWvGhhFJ7dY/belief-in-belief) are quite uncomfortable to the critical mind. My education has taught me that such beliefs (henceforth to be referred to as 'floating beliefs') are useless.

It's a patently rationalist mindset. Beliefs serve the unique purpose of anticipating future experience, ergo any belief that does not pay rent in predictive power deserves to be evicted. There's [a](https://www.lesswrong.com/posts/XrzQW69HpidzvBxGr/affective-death-spirals) [panoply](https://www.lesswrong.com/posts/fAuWLS7RKWD2npBFR/religion-s-claim-to-be-non-disprovable) [of](https://www.lesswrong.com/posts/PMr6f7ZocEWFtCYXj/is-humanism-a-religion-substitute) [posts](https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences) on LessWrong expounding on this perspective. Thus I am willing to admit that rationality, narrowly construed[^1], is incompatible with religion.

Conversely, what reason does rationality have? How can we be sure that the scientific method / Bayesian inference / induction will continue to work reliably? Do we just need to 'have faith'? Eliezer Yudkowsky [answers with a short nod](https://www.lesswrong.com/posts/zmSuDDFE4dicqd4Hg/you-only-need-faith-in-two-things):

> You only need faith in two things: That "induction works" has a non-super-exponentially-tiny prior probability, and that some single large ordinal is well-ordered. Anything else worth believing in is a deductive consequence of one or both.

I'm not here to doubt Eliezer's two things; I do believe in the scientific method as one of humanity's sharpest tools, and I do believe that behaving rationally is almost always optimal. I'm here to doubt the uniqueness claim: that these are the *only* two things I need faith in, that *anything else* worth believing in follows.

Ultimately, I think it reduces to some fundamental differences regarding how we interpret value in science. In my opinion, the purpose of a scientific theory is not to predict, but to understand. Predictive power can measure the accuracy of our understanding, but undestanding must also meet some standard of elegance, scale, and beauty. Jakob Schwichtenberg [illustrates](https://substack.com/@jakobschwichtenberg/p-156527602) a similar argument more convincingly than I can, but I think this model is more faithful to the history and current state of science than the Yudkowskian alternative.

Even if religious evidence is not admissible in court, there exist very compelling arguments illustrating our tendency to enforce legible structure onto [a frequently illegible reality](https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-called-legibility/).

If you're exactly like me, this should convince you that floating beliefs might not be evil. Even more scathingly, Eliezer assumes that we should minimize our assumptions whenever possible. (At least I don't see how this might follow from the first two claims, but I'd be happy to be proven wrong on this). I will admit this assumption is still weaker than "Christ died for your sins", but it's likely closer than we think. This assumption-cutting desire shared by mathematicians and rationalists alike is somehow an incarnation of Occam's razor, and I recently published [a conspiracy theory](/formalism) that it has origins in Abrahamic thought, rather than Aristotle. And if you're exactly like me, you're probably unwilling to gamble on Occam's razor with your life, not to mention eternity. Even mathematicians have steered away from Occam's razor (although not without controversy). The axiom of choice is now widely accepted by the mathematical community despite being famously unintuitive and almost certainly an overestimation of humanity's capabilities, for the sake of mere mathematical convenience. Who wouldn't want infinite-dimensional vector spaces to have bases?

So what's one more axiom if it improves our integrity as cognitive agents? After all, hasn't the objective always been [applied](https://www.rationality.org/) [rationality](https://www.effectivealtruism.org/)? What's one more ounce of faith if it makes the difference between a sky full of stars and a handful of dust?

---

[^1]: I use the term 'rationality' in a much more restricted sense than you probably have in mind. I'm mostly referring to the modern rationality movement as pioneered by Eliezer Yudkowsky, documented by [LessWrong](https://www.lesswrong.com/) and beyond. I think this is the closest rationality has come to an enactable belief system, and it has deeply influenced the way I form beliefs.